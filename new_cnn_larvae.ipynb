{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_snippets torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jdZIsuOUE79g",
        "outputId": "37209146-adc2-46c6-97c6-3bc5e21963dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_snippets\n",
            "  Downloading torch_snippets-0.555-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Collecting plum-dispatch (from torch_snippets)\n",
            "  Downloading plum_dispatch-2.5.7-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (1.7.29)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (11.2.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (0.3.7)\n",
            "Collecting loguru (from torch_snippets)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (13.9.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (6.0.2)\n",
            "Requirement already satisfied: catalogue in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.0.10)\n",
            "Requirement already satisfied: confection in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (0.1.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.11.7)\n",
            "Collecting typing (from torch_snippets)\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (2.5.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (4.14.0)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (1.1.3)\n",
            "Collecting jsonlines (from torch_snippets)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting imgaug>=0.4.0 (from torch_snippets)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xmltodict (from torch_snippets)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting fuzzywuzzy (from torch_snippets)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (3.9.1)\n",
            "Collecting python-Levenshtein (from torch_snippets)\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pre-commit (from torch_snippets)\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting icecream (from torch_snippets)\n",
            "  Downloading icecream-2.1.5-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mergedeep (from torch_snippets)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting deepdiff (from torch_snippets)\n",
            "  Downloading deepdiff-8.5.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from torch_snippets) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (1.15.3)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (4.11.0.86)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (2.37.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->torch_snippets) (2.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->torch_snippets) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->torch_snippets) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->torch_snippets) (0.4.1)\n",
            "Collecting orderly-set<6,>=5.4.1 (from deepdiff->torch_snippets)\n",
            "  Downloading orderly_set-5.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastcore->torch_snippets) (24.2)\n",
            "Collecting colorama>=0.3.9 (from icecream->torch_snippets)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from icecream->torch_snippets) (2.19.2)\n",
            "Collecting executing>=2.1.0 (from icecream->torch_snippets)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream->torch_snippets)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->torch_snippets) (25.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch_snippets) (2.9.0.post0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->torch_snippets) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->torch_snippets) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->torch_snippets) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->torch_snippets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->torch_snippets) (2025.2)\n",
            "Collecting beartype>=0.16.2 (from plum-dispatch->torch_snippets)\n",
            "  Downloading beartype-0.21.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->torch_snippets) (3.0.0)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->torch_snippets)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->torch_snippets)\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->torch_snippets)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->torch_snippets)\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein->torch_snippets)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein->torch_snippets)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->torch_snippets) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->torch_snippets) (0.1.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch_snippets) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch_snippets) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch_snippets) (0.4)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->torch_snippets)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->torch_snippets) (3.18.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->torch_snippets) (4.3.8)\n",
            "Downloading torch_snippets-0.555-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.2/109.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-8.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading icecream-2.1.5-py3-none-any.whl (14 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Downloading plum_dispatch-2.5.7-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading beartype-0.21.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading orderly_set-5.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=27192e63a4e86cdde3cfa5971c6e3e5ac6dfa8f0ac36c124ef8a342fbef58e41\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "Successfully built typing\n",
            "Installing collected packages: fuzzywuzzy, distlib, xmltodict, virtualenv, typing, rapidfuzz, orderly-set, nodeenv, mergedeep, loguru, jsonlines, identify, executing, colorama, cfgv, beartype, asttokens, pre-commit, Levenshtein, icecream, deepdiff, python-Levenshtein, plum-dispatch, imgaug, torch_snippets\n",
            "Successfully installed Levenshtein-0.27.1 asttokens-3.0.0 beartype-0.21.0 cfgv-3.4.0 colorama-0.4.6 deepdiff-8.5.0 distlib-0.3.9 executing-2.2.0 fuzzywuzzy-0.18.0 icecream-2.1.5 identify-2.6.12 imgaug-0.4.0 jsonlines-4.0.0 loguru-0.7.3 mergedeep-1.3.4 nodeenv-1.9.1 orderly-set-5.4.1 plum-dispatch-2.5.7 pre-commit-4.2.0 python-Levenshtein-0.27.1 rapidfuzz-3.13.0 torch_snippets-0.555 typing-3.7.4.3 virtualenv-20.31.2 xmltodict-0.14.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "bbcb6892239b4053b80e1f6c3e058161"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn markitdown"
      ],
      "metadata": {
        "id": "JOR4HXRWE-Es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5bc9cb-faac-4585-cc3d-f1ffcb6ade3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.8)\n",
            "Collecting markitdown\n",
            "  Downloading markitdown-0.1.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.6 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.6.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from markitdown) (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from markitdown) (3.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from markitdown) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown)\n",
            "  Downloading magika-0.6.2-py3-none-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Collecting markdownify (from markitdown)\n",
            "  Downloading markdownify-1.1.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from markitdown) (2.32.3)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown) (8.2.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting python-dotenv>=1.0.1 (from magika~=0.6.1->markitdown)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from pynndescent>=0.5->umap-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6->umap-learn) (3.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->markitdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->markitdown) (4.14.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.11/dist-packages (from markdownify->markitdown) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown) (2025.6.15)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.3.0)\n",
            "Downloading markitdown-0.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magika-0.6.2-py3-none-manylinux_2_28_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, humanfriendly, markdownify, coloredlogs, onnxruntime, magika, markitdown\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 magika-0.6.2 markdownify-1.1.0 markitdown-0.1.2 onnxruntime-1.22.0 python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sm9xRvZBzjR2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from torchsummary import summary\n",
        "from torch_snippets import *\n",
        "from torch_snippets.torch_loader import Report\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import umap\n",
        "import gc\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "#is GPU available?\n",
        "gpu = torch.cuda.is_available()\n",
        "\n",
        "#defining device where to to the computation\n",
        "device = torch.device(0) if gpu else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkqkRv0dHNG6",
        "outputId": "27cd7364-43d0-45e3-a372-07ca6628a370"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_dir   = '/content/drive/MyDrive/appsheet/Arquivos Colab/mo434/larvae'\n",
        "nclasses   = 2\n",
        "\n",
        "width       = 224\n",
        "height      = 224\n",
        "nchannels   = 3\n",
        "maxval      = 255.\n",
        "input_shape = (nchannels,height,width)\n",
        "\n",
        "data = glob(orig_dir+\"/*.png\")\n",
        "\n",
        "# Extract labels from filenames (0 for class 1, 1 for class 2)\n",
        "# This is crucial for the 'stratify' parameter\n",
        "labels = [int(f.split('/')[-1].split('_')[0]) - 1 for f in data]\n",
        "\n",
        "# The 'stratify=labels' argument ensures both sets have the same class proportion\n",
        "train_val_files, testset, train_val_labels, _ = train_test_split(\n",
        "    data, labels, test_size=0.30, random_state=42, stratify=labels)\n",
        "\n",
        "# now we split the temporary 70% set into the final training and validation sets.\n",
        "# The validation set is 0.20 of the original total, which is 0.20/0.70 of this temporary set.\n",
        "val_size_relative = 0.20 / (0.50 + 0.20)\n",
        "trainset, validset, _, _ = train_test_split(\n",
        "    train_val_files, train_val_labels, test_size=val_size_relative, random_state=42, stratify=train_val_labels)\n",
        "\n",
        "\n",
        "# verifying\n",
        "print(f\"Total: {len(data)}\")\n",
        "print(f\"Training: {len(trainset)}\")\n",
        "print(f\"Validation: {len(validset)}\")\n",
        "print(f\"Test: {len(testset)}\")\n",
        "\n",
        "# Set output model name\n",
        "model_name  = 'LarvaeCNN.pth'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcPL-Do3JMoR",
        "outputId": "85707a27-e026-4a70-970a-bfca5c83d6cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 1598\n",
            "Training: 798\n",
            "Validation: 320\n",
            "Test: 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular preprocessing transformation. The input is a PIL image, which after being resized,\n",
        "# it is converted into a tensor for normalization using the ImageNet mean and stdev parameters.\n",
        "\n",
        "prep = transforms.Compose([\n",
        "    transforms.Resize((height,width), interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Such transformations are applied everytime images are loaded from the filename lists in training, validation,\n",
        "# and test sets. We will do that during training, then by adding affine transformations and increasing the number 3\n",
        "# of epochs, we are actually implementing data augmentation.\n",
        "\n",
        "aug = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05,0.10), scale=(0.9,1.1), shear=(-2,2),\n",
        "                            interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                            fill=0),\n",
        "    transforms.CenterCrop(250),\n",
        "    transforms.Resize((height,width), interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Create an image dataset by applying one of the preprocessing transformations above\n",
        "\n",
        "class ImageDataset(): # there are three mandatory functions: init, len, getitem\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        # it gets the image true labels and set the preprocessing transformation\n",
        "        self.dataset   = dataset\n",
        "        self.targets   = [int(str(x).split(\"/\")[-1].split(\"_\")[0])-1 for x in self.dataset]\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.dataset)\n",
        "    def __getitem__(self, ix): # returns the item at position ix\n",
        "        filename = self.dataset[ix]\n",
        "        target   = self.targets[ix]\n",
        "        image    = Image.open(filename) # It is a PIL image\n",
        "        if (self.transform is not None):\n",
        "            image = self.transform(image)\n",
        "        else: # just reshape the image as a tensor with nchannels, height, width\n",
        "            image = torch.from_numpy(np.array(image)).permute(2,0,1).float()\n",
        "        return(image,target)"
      ],
      "metadata": {
        "id": "PSJ4e1MPJg7E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = ImageDataset(trainset, aug) # verify the difference with and wothout data augmentation\n",
        "validset = ImageDataset(validset, prep)\n",
        "testset  = ImageDataset(testset, prep)"
      ],
      "metadata": {
        "id": "W5ZrmuUMJlDo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize images from the trainset\n",
        "\n",
        "print(\"Number of images:\", len(trainset))\n",
        "image, target = trainset[4] # it executes getitem\n",
        "image     = image.permute(1,2,0).numpy()\n",
        "image     = 255*(image - np.min(image))/(np.max(image)-np.min(image))\n",
        "image     = image.astype('uint8')\n",
        "print(\"Images are {}x{}x{}\".format(width,height,nchannels))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "print(\"Class of the image: \", target+1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "Q6M1ooWkJqct",
        "outputId": "49724205-a492-4276-b14d-c4660dce62db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 798\n",
            "Images are 224x224x3\n",
            "Class of the image:  1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 32\n",
        "trainload = DataLoader(trainset, batch_size=batchsize, shuffle=True)\n",
        "testload  = DataLoader(testset, batch_size=batchsize, shuffle=True)\n",
        "validload = DataLoader(validset, batch_size=batchsize, shuffle=True)\n",
        "\n",
        "next(iter(trainload)) # inspect next item in the trainload"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FcL5vgvJrh_",
        "outputId": "c3716981-e88d-4de2-9f8a-4204c5059997"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           ...,\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
              " \n",
              "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           ...,\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
              " \n",
              "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           ...,\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
              " \n",
              " \n",
              "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           ...,\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
              " \n",
              "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           ...,\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
              " \n",
              "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           ...,\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
              " \n",
              " \n",
              "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           ...,\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
              " \n",
              "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           ...,\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
              " \n",
              "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           ...,\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           ...,\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
              " \n",
              "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           ...,\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
              " \n",
              "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           ...,\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
              " \n",
              " \n",
              "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           ...,\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
              " \n",
              "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           ...,\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
              " \n",
              "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           ...,\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
              " \n",
              " \n",
              "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           ...,\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
              " \n",
              "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           ...,\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
              " \n",
              "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           ...,\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]]),\n",
              " tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "         1, 1, 0, 1, 1, 0, 1, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Residual Blocks to the net"
      ],
      "metadata": {
        "id": "CXSAcp4bNr6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual block with two convolutional layers.\n",
        "    Includes a shortcut connection that adds the input to the output.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # main path will have two convolutions\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        # shortcut connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_block(x) + self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class LarvaNetV3(nn.Module):\n",
        "    \"\"\"\n",
        "    A new version of the LarvaNet using Residual Blocks.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(LarvaNetV3, self).__init__()\n",
        "\n",
        "        # Initial convolution layer (similar to ResNet architecture)\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], self.in_channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(self.in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        ) # Output size: 224 -> 112 -> 56x56\n",
        "\n",
        "        # Stacking Residual Blocks\n",
        "        self.layer1 = self._make_layer(ResidualBlock, 64, num_blocks=2, stride=1)  # Output: 56x56\n",
        "        self.layer2 = self._make_layer(ResidualBlock, 128, num_blocks=2, stride=2) # Output: 28x28\n",
        "        self.layer3 = self._make_layer(ResidualBlock, 256, num_blocks=2, stride=2) # Output: 14x14\n",
        "        self.layer4 = self._make_layer(ResidualBlock, 512, num_blocks=2, stride=2) # Output: 7x7\n",
        "\n",
        "        # Classifier part\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        # Helper function to create a layer of residual blocks\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, s))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "k6SzWhaPJvM-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v3 = LarvaNetV3(input_shape, nclasses).to(device)\n",
        "summary(model_v3, input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrKjUO_TJ6V2",
        "outputId": "5d509605-ad2a-4b7b-b2b7-a0561b2cec2b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "    ResidualBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "    ResidualBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "    ResidualBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "    ResidualBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "    ResidualBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "    ResidualBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 11,177,538\n",
            "Trainable params: 11,177,538\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Criterion(model, preds, targets):\n",
        "    ce            = nn.CrossEntropyLoss().to(device)\n",
        "    loss          = ce(preds, targets.long())\n",
        "    # add l2_regularization\n",
        "    l2_regularization = 0\n",
        "    for param in model.parameters():\n",
        "        l2_regularization += torch.norm(param,2)\n",
        "    loss += 0.0001*l2_regularization # 0.0001 is the weight_decay\n",
        "    # compute mean accuracy in the batch\n",
        "    pred_labels   = torch.max(preds, 1)[1] # same as argmax\n",
        "    acc           = torch.sum(pred_labels == targets.data)\n",
        "    n             = pred_labels.size(0)\n",
        "    acc           = acc/n\n",
        "    return loss, acc\n",
        "\n",
        "\n",
        "criterion = Criterion"
      ],
      "metadata": {
        "id": "zQgvNIXfJ9qV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_v3    = optim.Adam(model_v3.parameters(), lr=1e-4)\n",
        "lr_scheduler_v3 = optim.lr_scheduler.StepLR(optimizer_v3, step_size=25, gamma=0.9)"
      ],
      "metadata": {
        "id": "qvUIi7kZKE-t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(model, data, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    ims, targets = data\n",
        "    ims     = ims.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    preds   = model(ims)\n",
        "    loss, acc = criterion(model, preds, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return loss.item(), acc.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_batch(model, data, criterion, device):\n",
        "    model.eval()\n",
        "    ims, targets = data\n",
        "    ims     = ims.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    preds   = model(ims)\n",
        "    loss, acc = criterion(model, preds, targets)\n",
        "    return loss.item(), acc.item()"
      ],
      "metadata": {
        "id": "EOT6N_IVKMxw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 15 # Number of epochs to wait for improvement before stopping\n",
        "patience_counter = 0\n",
        "best_val_loss = float('inf') # Initialize best validation loss to infinity\n",
        "best_model_weights = None\n",
        "\n",
        "n_epochs = 100\n",
        "log = Report(n_epochs)\n",
        "\n",
        "\n",
        "for ex in range(n_epochs):\n",
        "\n",
        "\n",
        "    running_trn_loss = 0.0\n",
        "    running_trn_acc = 0.0\n",
        "    N = len(trainload)\n",
        "    for bx, data in enumerate(trainload):\n",
        "        loss, acc = train_batch(model_v3, data, optimizer_v3, criterion, device) # Using model_v3 and optimizer_v3\n",
        "        running_trn_loss += loss\n",
        "        running_trn_acc += acc\n",
        "        log.record((ex+(bx+1)/N), trn_loss=loss, trn_acc=acc, end='\\r')\n",
        "    epoch_trn_loss = running_trn_loss / N\n",
        "    epoch_trn_acc = running_trn_acc / N\n",
        "\n",
        "\n",
        "    running_val_loss = 0.0\n",
        "    running_val_acc = 0.0\n",
        "    N_val = len(validload)\n",
        "    val_preds_list = []\n",
        "    val_targets_list = []\n",
        "\n",
        "    for bx, data in enumerate(validload):\n",
        "        loss, acc = validate_batch(model_v3, data, criterion, device)\n",
        "        running_val_loss += loss\n",
        "        running_val_acc += acc\n",
        "        log.record((ex+(bx+1)/N_val), val_loss=loss, val_acc=acc, end='\\r')\n",
        "\n",
        "        model_v3.eval()\n",
        "        with torch.no_grad():\n",
        "            ims, targets = data\n",
        "            ims, targets = ims.to(device), targets.to(device)\n",
        "            preds = model_v3(ims)\n",
        "            pred_labels = torch.max(preds, 1)[1]\n",
        "            val_preds_list.extend(pred_labels.cpu().numpy())\n",
        "            val_targets_list.extend(targets.cpu().numpy())\n",
        "\n",
        "    epoch_val_loss = running_val_loss / N_val\n",
        "    epoch_val_acc = running_val_acc / N_val\n",
        "    kappa = cohen_kappa_score(val_targets_list, val_preds_list)\n",
        "    log.record(ex+1, val_kappa=kappa, end='\\r')\n",
        "\n",
        "\n",
        "    if (ex + 1) % 5 == 0:\n",
        "            print(f\"--EPOCH: {ex+1}  \",\n",
        "                  f\"Trn_Loss: {epoch_trn_loss:.4f}  \",\n",
        "                  f\"Trn_Acc: {epoch_trn_acc:.4f}  \",\n",
        "                  f\"Val_Loss: {epoch_val_loss:.4f}  \",\n",
        "                  f\"Val_Acc: {epoch_val_acc:.4f}  \",\n",
        "                  f\"Val_Kappa: {kappa:.4f}  \",\n",
        "                  f\"Patience: {patience_counter}/{patience}\")\n",
        "\n",
        "    lr_scheduler_v3.step()\n",
        "\n",
        "\n",
        "    if epoch_val_loss < best_val_loss:\n",
        "        # if validation loss improves, save the model state and reset the counter\n",
        "        best_val_loss = epoch_val_loss\n",
        "        best_model_weights = model_v3.state_dict().copy() # Save the best model weights\n",
        "        patience_counter = 0\n",
        "        print(f\"Validation loss improved. Best val_loss: {best_val_loss:.4f}\")\n",
        "    else:\n",
        "        # if validation loss does not improve, increment the counter\n",
        "        patience_counter += 1\n",
        "        print(f\"Validation loss did not improve. Patience counter: {patience_counter}/{patience}\")\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        # If the counter reaches the patience limit, stop training\n",
        "        print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
        "        break\n",
        "\n",
        "\n",
        "if best_model_weights:\n",
        "    print(\"\\nLoading best model weights found during training.\")\n",
        "    model_v3.load_state_dict(best_model_weights)\n",
        "\n",
        "print(\"\\nTraining finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_igROgJiKOyh",
        "outputId": "3dac0703-17c0-40ce-ff15-31cc0ffdc44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1.000  val_kappa: 0.801  (11.92s - 1180.34s remaining)Validation loss improved. Best val_loss: 0.2120\n",
            "EPOCH: 2.000  val_kappa: 0.706  (23.93s - 1172.49s remaining)Validation loss did not improve. Patience counter: 1/15\n",
            "EPOCH: 3.000  val_kappa: 0.447  (35.88s - 1160.22s remaining)Validation loss did not improve. Patience counter: 2/15\n",
            "EPOCH: 4.000  val_kappa: 0.706  (48.71s - 1169.07s remaining)Validation loss did not improve. Patience counter: 3/15\n",
            "EPOCH: 5.000  val_kappa: 0.158  (61.52s - 1168.80s remaining)--EPOCH: 5   Trn_Loss: 0.1251   Trn_Acc: 0.9688   Val_Loss: 0.6456   Val_Acc: 0.8594   Val_Kappa: 0.1579   Patience: 3/15\n",
            "Validation loss did not improve. Patience counter: 4/15\n",
            "EPOCH: 6.000  val_kappa: 0.558  (73.68s - 1154.33s remaining)Validation loss did not improve. Patience counter: 5/15\n",
            "EPOCH: 7.000  val_kappa: 0.216  (85.92s - 1141.47s remaining)Validation loss did not improve. Patience counter: 6/15\n",
            "EPOCH: 8.000  val_kappa: 0.755  (98.04s - 1127.42s remaining)Validation loss did not improve. Patience counter: 7/15\n",
            "EPOCH: 9.000  val_kappa: 0.544  (111.62s - 1128.60s remaining)Validation loss did not improve. Patience counter: 8/15\n",
            "EPOCH: 10.000  val_kappa: 0.519  (123.99s - 1115.94s remaining)--EPOCH: 10   Trn_Loss: 0.1137   Trn_Acc: 0.9738   Val_Loss: 0.3465   Val_Acc: 0.9000   Val_Kappa: 0.5188   Patience: 8/15\n",
            "Validation loss did not improve. Patience counter: 9/15\n",
            "EPOCH: 10.600  trn_loss: 0.140  trn_acc: 0.969  (129.60s - 1093.06s remaining)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BrEqZ8TXV6a8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}